{
  "transcript": "Hi everybody, welcome to Stanford CS two hundred and twenty four N, also known as Link 284 natural Language Processing with Deep Learning. I'm Christopher Manning and I'm the main instructor for this class. So what we hope to do today is to dive right in. So I'm going to spend about ten minutes talking about the course and then we're going to get straight into content for reasons I'll explain in a minute. So we'll talk about human language and word meaning. I'll then introduce the ideas of the word to vet algorithm for learning word meaning and then going from there we'll kind of concretely work through how you can work out objective function gradients with respect to the word to vet algorithm and say a teeny bit about how optimization works. And then right at the end of the class I then want to spend a little bit of time giving you a sense of how these word vectors work and what you can do with them. So really the key learning for today is I want to give you a sense of how amazing deep learning word vectors are. So we have this really surprising result that word meaning can be represented not perfectly but really rather well by a large vector of real numbers and that's sort of in a way a commonplace of the last decade of deep learning but it flies in the face of thousands of years of tradition and it's really rather an unexpected result to start focusing on. Okay, so quickly what do we hope to teach in this course? So we've got three primary goals. The first is to teach you the foundations, a good deep understanding of the effect of modern methods for deep learning applied to NLP. So we are going to start with and go through the basics and then go on to key methods that are used in NLP current networks, attention transformers and things like that. We want to do something more than just that. We'd also like to give you some sense of a big picture understanding of human languages and what are the reasons for why they're actually quite difficult to understand and produce even though humans seem to do it easily. Now obviously if you really want to learn a lot about this topic you should enroll in and go and start doing some classes in the linguistics department. But nevertheless, for a lot of you this is the only human language content you'll see during your master's degree or whatever and so we do hope to spend a bit of time on that starting today. And then finally we want to give you an understanding of an ability to build systems in PyTorch for some of the major problems in NLP. So we'll look at learning word meanings, dependency, parsing, machine translation, question answering, let's dive into human language. Once upon a time I had a lot longer introduction that gave lots of examples about how human languages can be misunderstood and complex. I'll show a few of those examples in later lectures. But since. Right for today we're going to be focused on word meaning. I thought I'd just give one example which comes from a very nice Xkcd cartoon and that isn't sort of about some of the sort of syntactic ambiguities of sentences. But instead it's really emphasizing the important point that languages a social system constructed and interpreted by people. And that's part of health. And it changes as people decide to adapt its construction. And that's part of the reason why human languages are great as an adaptive system for human beings, but difficult as a system for our computers to understand to this day. So in this conversation between the two women, one says, anyway, I could care less. And the other says, I think you mean you couldn't care less. Saying you could care less implies you care at least some amount. And the other one says, I don't know. We're these unbelievably complicated brains drifting through a void, trying in vain to connect with one another by blindly flinging words out into the darkness. Every choice of phrasing, spelling and tone and timing carries countless signals and contexts and subtexts and more. And every listener interprets those signals in their own way. Language isn't a formal system. Language is glorious chaos. You can never know for sure what any words will mean to anyone. All you can do is try to get better at guessing how your words affect people so you can have a chance of finding the ones that will make them feel something like what you want them to feel. Everything else is pointless. I assume you're giving me tips on how you interpret words because you want me to feel less alone. If so, then thank you, that means a lot. But if you're just running my sentences past some mental checklist so you can show off how well you know it, then I could care less. Okay? So that's ultimately what our goal is to have to do a better job at building computational systems that try to get better at guessing how their words will affect other people and what other people are meaning by the words that they choose to say. So an interesting thing about human language is it is a system that was constructed by human beings and it's a system that was constructed relatively recently in some sense. So in discussions of artificial intelligence, a lot of the time people focus a lot on human brains and the neurons buzzing by and this intelligence that's meant to be inside people's heads. But I just wanted to focus for a moment on the role of language. This is kind of controversial, but it's not necessarily the case that humans are much more intelligent than some of the higher rates like chimpanzees or bonobos, right? So chimpanzees and bonobos have been shown to be able to use pools to make plans. And in fact, chimps have much better short term memory than human beings do. So relative to that, if you look through the history of life on Earth, human beings develop language really recently. How recently we actually don't know because there's no fossils that say okay, here's a language speaker. But most people estimate that language arose for human beings sort of somewhere in the range of 100,000 to a million years ago. Okay, that's a while ago. But compared to the process of evolution of life on Earth, that's kind of blinking an eyelid. But that power communication between human beings quickly set off our ascendancy over other creatures. So it's kind of interesting that the ultimate power turned out not to be having poisonous things or being super fast or super big, but having the ability to communicate with other members of your tribe. If it was much more recently again that humans develop writing which allowed knowledge to be communicated across distances of time and space and so that's only about 5000 years old, the power of writing. So in just a few thousand years, the ability to preserve and share knowledge took us from the Bronze Age to the smartphones and tablets of today. So a key question for artificial intelligence and human computer interaction is how to get computers to be able to understand the information conveyed in human languages simultaneously. Artificial intelligence requires computers with the knowledge of people. Fortunately, now our AI systems might be able to benefit from a virtuous cycle. We need knowledge to understand language and people well. But it's also the case that a lot of that knowledge is contained in language spread out across the of books and webpages of the world. And that's one of the things we're going to look at in this course is how that we can sort of build on that.",
  "chapters": [
      {
          "summary": "Christopher Manning is the main instructor for the Link 284 Natural Language Processing with Deep Learning class at Stanford CS 2100 and twenty-four N. Today he will talk about human language and word meaning, introduce the ideas of the word to vet algorithm for learning word meaning and work through how you can work out objective function gradients with respect to the word.",
          "headline": "Christopher Manning is the main instructor for the Link 284 Natural Language Processing with Deep Learning class at Stanford CS 2100 and twenty-four N. He will talk about human language and word meaning today.",
          "gist": "Intro to the course.",
          "start": 5470,
          "end": 102320
      },
      {
          "summary": "The course aims to teach you the foundations of modern methods for deep learning applied to NLP. It also wants to give you an understanding of the big picture understanding of human languages. It will also teach you how to build systems in PyTorch for some of the major problems in NLP, such as word meanings, dependency, parsing and machine translation.",
          "headline": "The course aims to teach you the foundations of modern methods for deep learning applied to NLP.",
          "gist": "What do we hope to teach.",
          "start": 103070,
          "end": 206610
      },
      {
          "summary": "Today's talk is about the meaning of words and their construction. It's important to understand that languages are social system constructed and interpreted by people. Human languages are great as an adaptive system for human beings but difficult as a system for computers to understand to this day. Language arose for humans 100000 to a million years ago. The ultimate power of human beings is communication between people.",
          "headline": "Today's talk is about the meaning of words and their construction.",
          "gist": "Word meaning and health.",
          "start": 206720,
          "end": 549360
      }
  ],
  "highlights": null
}